<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-reference/core-faqs">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v0.0.0-5124">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XXX"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-XXX",{})</script><title data-rh="true">FAQs | Firehose</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://goto.github.io//firehose/reference/core-faqs"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="FAQs | Firehose"><meta data-rh="true" name="description" content="What problems does Firehose solve?"><meta data-rh="true" property="og:description" content="What problems does Firehose solve?"><link data-rh="true" rel="icon" href="/firehose/assets/favicon.ico"><link data-rh="true" rel="canonical" href="https://goto.github.io//firehose/reference/core-faqs"><link data-rh="true" rel="alternate" href="https://goto.github.io//firehose/reference/core-faqs" hreflang="en"><link data-rh="true" rel="alternate" href="https://goto.github.io//firehose/reference/core-faqs" hreflang="x-default"><link rel="stylesheet" href="/firehose/assets/css/styles.620b4533.css">
<link rel="preload" href="/firehose/assets/js/runtime~main.01adef25.js" as="script">
<link rel="preload" href="/firehose/assets/js/main.d3e659f8.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#222;color:#eee" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="announcementBarContent_xLdY">⭐️ If you like Firehose, give it a star on <a target="_blank" rel="noopener noreferrer" href="https://github.com/goto/firehose">GitHub</a>! ⭐</div><button type="button" class="clean-btn close announcementBarClose_gvF7" aria-label="Close"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/firehose/"><div class="navbar__logo"><img src="/firehose/firehose.png" alt="Firehose" class="themedImage_ToTc themedImage--light_HNdA"><img src="/firehose/firehose.png" alt="Firehose" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Firehose</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/firehose/">Documentation</a><a class="navbar__item navbar__link" href="/firehose/support">Support</a><a href="https://bit.ly/2RzPbtn" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-slack-link"></a><a href="https://github.com/goto/firehose" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar-item-github"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/firehose/"><img src="/firehose/firehose.png" alt="Firehose" class="themedImage_ToTc themedImage--light_HNdA"><img src="/firehose/firehose.png" alt="Firehose" class="themedImage_ToTc themedImage--dark_i4oU"><b>Firehose</b></a><nav class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/firehose/">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="true" href="/firehose/guides/create_firehose">Guides</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/guides/create_firehose">Creating Firehose</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/guides/json-based-filters">JSON-based Filters</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/guides/jexl-based-filters">JEXL-based Filters</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/guides/deployment">Deployment</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/guides/manage">Troubleshooting</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="true" href="/firehose/sinks/httpv2-sink">Sinks</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/httpv2-sink">HttpV2 Sink</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/http-sink">HTTP</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/grpc-sink">GRPC</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/jdbc-sink">JDBC</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/bigquery-sink">BigQuery</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/influxdb-sink">InfluxDB</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/prometheus-sink">Prometheus</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/mongo-sink">MongoDB</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/redis-sink">Redis Sink</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/elasticsearch-sink">Elasticsearch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/blob-sink">Blob</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/firehose/concepts/overview">Concepts</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/firehose/advance/generic">Advance</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/firehose/reference/metrics">Reference</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/reference/metrics">Metrics</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/firehose/reference/core-faqs">FAQs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/reference/faq">Frequently Asked Questions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/reference/glossary">Glossary</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/firehose/contribute/contribution">Contribute</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/firehose/roadmap">Roadmap</a></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_GujU"><div class="docItemContainer_Adtb"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_aoJ5"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>FAQs</h1><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-problems-does-firehose-solve">What problems does Firehose solve?<a class="hash-link" href="#what-problems-does-firehose-solve" title="Direct link to heading">​</a></h2><p>Every micro-service needs its own sink to be developed for such common operations as streaming data from Kafka to data lakes or other endpoints, along with real-time filtering, parsing, and monitoring of the sink.</p><p>With Firehose, you don&#x27;t need to write sink code for every such microservice, or manage resources to sink data from Kafka server to your database/service endpoint. Having provided all the configuration parameters of the sink, Firehose will create, manage and monitor one for you. It also automatically scales to match the throughput of your data and requires no ongoing administration.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="which-java-versions-does-firehose-work-with">Which Java versions does Firehose work with?<a class="hash-link" href="#which-java-versions-does-firehose-work-with" title="Direct link to heading">​</a></h2><p>Firehose has been built and tested to work with Java SE Development Kit 1.8.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-does-the-execution-work">How does the execution work?<a class="hash-link" href="#how-does-the-execution-work" title="Direct link to heading">​</a></h2><p>Firehose has the capability to run parallelly on threads. Each thread does the following:</p><ul><li>Get messages from Kafka</li><li>Filter the messages <!-- -->(<!-- -->optional<!-- -->)</li><li>Push these messages to sink</li><li>All the existing sink types follow the same contract/lifecycle defined in <code>AbstractSink.java</code>. It consists of two stages:<ul><li>Prepare: Transformation over-filtered messages’ list to prepare the sink-specific insert/update client requests.</li><li>Execute: Requests created in the Prepare stage are executed at this step and a list of failed messages is returned <!-- -->(<!-- -->if any<!-- -->)<!-- --> for retry.</li></ul></li><li>In case push fails and DLQ is:<ul><li>enabled: Firehose keeps on retrying for the configured number of attempts before the messages got pushed to DLQ Kafka topic</li><li>disabled: Firehose keeps on retrying until it receives a success code</li></ul></li><li>Captures telemetry and success/failure events and send them to Telegraf</li><li>Repeat the process</li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="can-i-do-any-transformationsfor-example-filter-before-sending-the-data-to-sink">Can I do any transformations<!-- -->(<!-- -->for example filter<!-- -->)<!-- --> before sending the data to sink?<a class="hash-link" href="#can-i-do-any-transformationsfor-example-filter-before-sending-the-data-to-sink" title="Direct link to heading">​</a></h2><p>Yes, Firehose provides JEXL based filters based on the fields in key or message of the Kafka record. Read the <a href="/firehose/concepts/filters">Filters</a> section for further details.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-to-optimize-parallelism-based-on-input-rate-of-kafka-messages">How to optimize parallelism based on input rate of Kafka messages?<a class="hash-link" href="#how-to-optimize-parallelism-based-on-input-rate-of-kafka-messages" title="Direct link to heading">​</a></h2><p>You can increase the workers in the Firehose which will effectively multiply the number of records being processed by Firehose. However, please be mindful of the fact that your sink also needs to be able to process this higher volume of data being pushed to it. Because if it is not, then this will only compound the problem of increasing lag.</p><p>Adding some sort of a filter condition in the Firehose to ignore unnecessary messages in the topic would help you bring down the volume of data being processed by the sink.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-is-the-retry-mechanism-in-firehose-what-kind-of-retry-strategies-are-supported-">What is the retry mechanism in Firehose? What kind of retry strategies are supported ?<a class="hash-link" href="#what-is-the-retry-mechanism-in-firehose-what-kind-of-retry-strategies-are-supported-" title="Direct link to heading">​</a></h2><p>In case push fails and DLQ <!-- -->(<!-- -->Dead Letter Queue<!-- -->)<!-- --> is:</p><ul><li>enabled: Firehose keeps on retrying for the configured number of attempts before the messages got pushed to DLQ Kafka topic</li><li>disabled: Firehose keeps on retrying until it receives a success code</li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="which-kafka-client-configs-are-available-">Which Kafka Client configs are available ?<a class="hash-link" href="#which-kafka-client-configs-are-available-" title="Direct link to heading">​</a></h2><p>Firehose provides various Kafka client configurations. Refer <a href="/firehose/advance/generic">Generic Configurations</a> section for details on configuration related to Kafka Consumer.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-all-data-formats-are-supported-">What all data formats are supported ?<a class="hash-link" href="#what-all-data-formats-are-supported-" title="Direct link to heading">​</a></h2><p>Elasticsearch , Bigquery and MongoDB sink support both JSON and Protobuf as the input schema. For other sinks, we currently support only Protobuf. Support for JSON and Avro is planned and incorporated in our roadmap. Please refer to our Roadmap section for more details.</p><p>Protocol buffers are Google&#x27;s language-neutral, platform-neutral, extensible mechanism for serializing structured data. Data streams on Kafka topics are bound to a Protobuf schema.</p><p>Follow the instructions in <a href="https://developers.google.com/protocol-buffers/docs/javatutorial" target="_blank" rel="noopener noreferrer">this article</a> on how to create, compile and serialize a Protobuf object to send it to a binary OutputStream. Refer <a href="https://developers.google.com/protocol-buffers/docs/proto3" target="_blank" rel="noopener noreferrer">this guide</a> for detailed Protobuf syntax and rules to create a <code>.proto</code> file</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="is-there-any-code-snippet-which-shows-how-i-can-produce-sample-message-in-supported-data-format-">Is there any code snippet which shows how i can produce sample message in supported data format ?<a class="hash-link" href="#is-there-any-code-snippet-which-shows-how-i-can-produce-sample-message-in-supported-data-format-" title="Direct link to heading">​</a></h2><p>Following is an example to demonstrate how to create a Protobuf message and then produce it to a Kafka cluster. Firstly, create a <code>.proto</code> file containing all the required field names and their corresponding integer tags. Save it in a new file named <code>person.proto</code></p><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">syntax = &quot;proto2&quot;;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">package tutorial;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">option java_multiple_files = true;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">option java_package = &quot;com.example.tutorial.protos&quot;;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">option java_outer_classname = &quot;PersonProtos&quot;;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">message Person {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  optional string name = 1;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  optional int32 id = 2;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  optional string email = 3;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  enum PhoneType {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    MOBILE = 0;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    HOME = 1;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    WORK = 2;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  message PhoneNumber {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    optional string number = 1;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    optional PhoneType type = 2 [default = HOME];</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repeated PhoneNumber phones = 4;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Next, compile your <code>.proto</code> file using Protobuf compiler i.e. <code>protoc</code>.This will generate Person ,PersonOrBuilder and PersonProtos Java source files. Specify the source directory <!-- -->(<!-- -->where your application&#x27;s source code lives – the current directory is used if you don&#x27;t provide a value<!-- -->)<!-- -->, the destination directory <!-- -->(<!-- -->where you want the generated code to go; often the same as <code>$SRC_DIR</code>)<!-- -->, and the path to your <code>.proto</code></p><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">protoc -I=$SRC_DIR --java_out=$DST_DIR $SRC_DIR/person.proto</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Lastly, add the following lines in your Java code to generate a POJO <!-- -->(<!-- -->Plain Old Java Object<!-- -->)<!-- --> of the Person proto class and serialize it to a byte array, using the <code>toByteArray()</code> method of the <a href="https://www.javadoc.io/static/com.google.protobuf/protobuf-java/3.5.1/com/google/protobuf/GeneratedMessageV3.html" target="_blank" rel="noopener noreferrer">com.google.protobuf.GeneratedMessageV3 </a> class. The byte array is then sent to the Kafka cluster by the producer.</p><div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">KafkaProducer&lt;byte[], byte[]&gt; producer = new KafkaProducer&lt;&gt;(properties);</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Person john = Person.newBuilder()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                .setId(87182872)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                .setName(&quot;John Doe&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                .setEmail(&quot;jdoe@example.com&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                .addPhones(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        Person.PhoneNumber.newBuilder()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                .setNumber(&quot;555-4321&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                .setType(Person.PhoneType.HOME))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                .build();</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">producer.send(new ProducerRecord&lt;byte[], byte[]&gt;(topicName, john.toByteArray()));</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Refer <a href="https://developers.google.com/protocol-buffers" target="_blank" rel="noopener noreferrer">https://developers.google.com/protocol-buffers</a> for more info on how to create protobufs.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="can-we-select-particular-fields-from-the-incoming-message-">Can we select particular fields from the incoming message ?<a class="hash-link" href="#can-we-select-particular-fields-from-the-incoming-message-" title="Direct link to heading">​</a></h2><p>Firehose will send all the fields of the incoming messages to the specified sink. But you can configure your sink destination/ database to consume only the required fields.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-can-i-handle-consumer-lag-">How can I handle consumer lag ?<a class="hash-link" href="#how-can-i-handle-consumer-lag-" title="Direct link to heading">​</a></h2><ul><li>When it comes to decreasing the topic lag, it often helps to have the environment variable - <a href="/firehose/advance/generic#source_kafka_consumer_config_max_poll_records"><code>SOURCE_KAFKA_CONSUMER_CONFIG_MAX_POLL_RECORDS</code></a> to be increased from the default of 500 to something higher which will tell the Kafka Consumer to consume more messages in a single poll.</li><li>Additionally, you can increase the workers in the Firehose which will effectively multiply the number of records being processed by Firehose.</li><li>Alternatively, if your underlying sink is not able to handle increased <!-- -->(<!-- -->or default<!-- -->)<!-- --> volume of data being pushed to it, adding some sort of a filter condition in the Firehose to ignore unnecessary messages in the topic would help you bring down the volume of data being processed by the sink.</li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-is-stencil-in-context-of-firehose-">What is Stencil in context of Firehose ?<a class="hash-link" href="#what-is-stencil-in-context-of-firehose-" title="Direct link to heading">​</a></h2><p>Stencil API is a dynamic schema registry for hosting and managing versions of Protobuf descriptors. The schema handling i.e., find the mapped schema for the topic, downloading the descriptors, and dynamically being notified of/updating with the latest schema is abstracted through the Stencil library.</p><p>The Stencil Client is a proprietary library that provides an abstraction layer, for schema handling. Schema Caching, dynamic schema updates are features of the stencil client library.</p><p>Refer <a href="https://goto.gitbook.io/stencil/" target="_blank" rel="noopener noreferrer">this article</a> for further information of the features, configuration and deployment instructions of the Stencil API. Source code of Stencil Server and Client API can be found in its <a href="https://github.com/goto/stencil" target="_blank" rel="noopener noreferrer">Github repository</a>.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-do-i-configure-protobuf-needed-to-consume-">How do I configure Protobuf needed to consume ?<a class="hash-link" href="#how-do-i-configure-protobuf-needed-to-consume-" title="Direct link to heading">​</a></h2><p>Generated Protobuf Descriptors are hosted behind an Stencil server artifactory/HTTP endpoint. This endpoint URL and the ProtoDescriptor class that the Firehose deployment should use to deserialize raw data with is configured in Firehose in the environment variables<code>SCHEMA_REGISTRY_STENCIL_URLS</code>and<code>INPUT_SCHEMA_PROTO_CLASS</code> respectively .</p><p>The Proto Descriptor Set of the Kafka messages must be uploaded to the Stencil server. Refer <a href="https://github.com/goto/stencil/tree/master/server#readme" target="_blank" rel="noopener noreferrer">this guide</a> on how to setup and configure the Stencil server.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="can-we-select-particular-fields-from-the-input-message-">Can we select particular fields from the input message ?<a class="hash-link" href="#can-we-select-particular-fields-from-the-input-message-" title="Direct link to heading">​</a></h2><p>No, all fields from the input key/message will be sent by Firehose to the Sink. But you can configure your service endpoint or database to consume only those fields which are required.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="why-protobuf--can-it-support-other-formats-like-json-and-avro-">Why Protobuf ? Can it support other formats like JSON and Avro ?<a class="hash-link" href="#why-protobuf--can-it-support-other-formats-like-json-and-avro-" title="Direct link to heading">​</a></h2><p>Protocol buffers are Google&#x27;s language-neutral, platform-neutral, extensible mechanism for serializing structured data. Data streams on Kafka topics are bound to a Protobuf schema. Protobuf is much more lightweight that other schema formats like JSON, since it encodes the keys in the message to integers.</p><p>Elasticsearch, Bigquery and MongoDB sink support both JSON and Protobuf as the input schema.</p><p>For other sinks, we currently support only Protobuf. Support for JSON and Avro is planned and incorporated in our roadmap. Please refer to our Roadmap section for more details.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="will-i-have-any-data-loss-if-my-firehose-fails-">Will I have any data loss if my Firehose fails ?<a class="hash-link" href="#will-i-have-any-data-loss-if-my-firehose-fails-" title="Direct link to heading">​</a></h2><p>After a batch of messages is sent successfully, Firehose commits the offset before the consumer polls another batch from Kafka. Thus, failed messages are not committed.</p><p>So, when Firehose is restarted, the Kafka Consumer automatically starts pulling messages from the last committed offset of the consumer group. So, no data loss occurs when an instance of Firehose fails.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-does-firehose-handle-failed-messages-">How does Firehose handle failed messages ?<a class="hash-link" href="#how-does-firehose-handle-failed-messages-" title="Direct link to heading">​</a></h2><p>In case push fails and DLQ <!-- -->(<!-- -->Dead Letter Queue<!-- -->)<!-- --> is:</p><ul><li>enabled: Firehose keeps on retrying for the configured number of attempts before the messages got pushed to DLQ Kafka topic</li><li>disabled: Firehose keeps on retrying until it receives a success code</li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-does-commits-for-kafka-consumer-works-">How does commits for Kafka consumer works ?<a class="hash-link" href="#how-does-commits-for-kafka-consumer-works-" title="Direct link to heading">​</a></h2><p>After the messages are pulled successfully, Firehose commits the offset to the Kafka cluster.</p><p>If<code>SOURCE_KAFKA_ASYNC_COMMIT_ENABLE</code> is set to <code>true</code>then the KafkaConsumer commits the offset asynchronously and logs to the metric <code>SOURCE_KAFKA_MESSAGES_COMMIT_TOTAL</code> incrementing the counter <code>FAILURE_TAG</code> or <code>SUCCESS_TAG</code> depending on whether the commit was a success / failure.</p><p>If<code>SOURCE_KAFKA_ASYNC_COMMIT_ENABLE</code> is set to <code>false</code>then the KafkaConsumer commits the offset synchronously and execution is blocked until the commit either succeeds or throws an exception.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-all-metrics-are-available-to-monitor-the-kafka-consumer">What all metrics are available to monitor the Kafka consumer?<a class="hash-link" href="#what-all-metrics-are-available-to-monitor-the-kafka-consumer" title="Direct link to heading">​</a></h2><p>Firehose exposes critical metrics to monitor the health of your delivery streams and take any necessary actions. Refer the <a href="/firehose/reference/metrics">Metrics</a> section for further details on each metric.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-happens-if-my-firehose-gets-restarted">What happens if my Firehose gets restarted?<a class="hash-link" href="#what-happens-if-my-firehose-gets-restarted" title="Direct link to heading">​</a></h2><p>When Firehose is restarted, the Kafka Consumer automatically starts pulling messages from the last committed offset of the consumer group specified by the variable <code>SOURCE_KAFKA_CONSUMER_GROUP_ID</code></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-to-configure-the-filter-for-a-proto-field-based-on-some-data">How to configure the filter for a proto field based on some data?<a class="hash-link" href="#how-to-configure-the-filter-for-a-proto-field-based-on-some-data" title="Direct link to heading">​</a></h2><p>The environment variables <code>FILTER_DATA_SOURCE</code> , <code>FILTER_JEXL_EXPRESSION</code> and <code>FILTER_SCHEMA_PROTO_CLASS</code> need to be set for filters to work. The required filters need to be written in JEXL expression format. Refer <a href="/firehose/guides/json-based-filters">Using Filters</a> section for more details.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="can-i-perform-basic-arithmetic-operations-in-filters">Can I perform basic arithmetic operations in filters?<a class="hash-link" href="#can-i-perform-basic-arithmetic-operations-in-filters" title="Direct link to heading">​</a></h2><p>Yes, you can combine multiple fields of the key/message protobuf in a single JEXL expression and perform any arithmetic or logical operations between them. e.g - <code>sampleKey.getTime().getSeconds() * 1000 + sampleKey.getTime().getMillis() &gt; 22809</code></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="does-log-sink-work-for-any-complex-data-type-eg-array">Does log sink work for any complex data type e.g. array?<a class="hash-link" href="#does-log-sink-work-for-any-complex-data-type-eg-array" title="Direct link to heading">​</a></h2><p>Log Sink uses Logback and SL4J lobrary for logging to standard output. Thus, it&#x27;ll be able to log any complex data type by printing the String returned by the toString<!-- -->(<!-- -->)<!-- --> method of the object. Log sink will also work for arrays and be able to print all the array elements in comma-separated format, e.g. <code>[4, 3, 8]</code></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-are-the-use-cases-of-log-sink">What are the use-cases of log sink?<a class="hash-link" href="#what-are-the-use-cases-of-log-sink" title="Direct link to heading">​</a></h2><p>Firehose provides a log sink to make it easy to consume messages in <a href="https://en.wikipedia.org/wiki/Standard_streams#Standard_output_%28stdout%29" target="_blank" rel="noopener noreferrer">standard output</a>. Log sink can be used for debugging purposes and experimenting with various filters. It can also be used to test the latency and overall performance of the Firehose.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/goto/firehose/edit/master/docs/docs/reference/core-faqs.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_eYIM" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vbeJ"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/firehose/reference/metrics"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Metrics</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/firehose/reference/faq"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Frequently Asked Questions</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-problems-does-firehose-solve" class="table-of-contents__link toc-highlight">What problems does Firehose solve?</a></li><li><a href="#which-java-versions-does-firehose-work-with" class="table-of-contents__link toc-highlight">Which Java versions does Firehose work with?</a></li><li><a href="#how-does-the-execution-work" class="table-of-contents__link toc-highlight">How does the execution work?</a></li><li><a href="#can-i-do-any-transformationsfor-example-filter-before-sending-the-data-to-sink" class="table-of-contents__link toc-highlight">Can I do any transformations(for example filter) before sending the data to sink?</a></li><li><a href="#how-to-optimize-parallelism-based-on-input-rate-of-kafka-messages" class="table-of-contents__link toc-highlight">How to optimize parallelism based on input rate of Kafka messages?</a></li><li><a href="#what-is-the-retry-mechanism-in-firehose-what-kind-of-retry-strategies-are-supported-" class="table-of-contents__link toc-highlight">What is the retry mechanism in Firehose? What kind of retry strategies are supported ?</a></li><li><a href="#which-kafka-client-configs-are-available-" class="table-of-contents__link toc-highlight">Which Kafka Client configs are available ?</a></li><li><a href="#what-all-data-formats-are-supported-" class="table-of-contents__link toc-highlight">What all data formats are supported ?</a></li><li><a href="#is-there-any-code-snippet-which-shows-how-i-can-produce-sample-message-in-supported-data-format-" class="table-of-contents__link toc-highlight">Is there any code snippet which shows how i can produce sample message in supported data format ?</a></li><li><a href="#can-we-select-particular-fields-from-the-incoming-message-" class="table-of-contents__link toc-highlight">Can we select particular fields from the incoming message ?</a></li><li><a href="#how-can-i-handle-consumer-lag-" class="table-of-contents__link toc-highlight">How can I handle consumer lag ?</a></li><li><a href="#what-is-stencil-in-context-of-firehose-" class="table-of-contents__link toc-highlight">What is Stencil in context of Firehose ?</a></li><li><a href="#how-do-i-configure-protobuf-needed-to-consume-" class="table-of-contents__link toc-highlight">How do I configure Protobuf needed to consume ?</a></li><li><a href="#can-we-select-particular-fields-from-the-input-message-" class="table-of-contents__link toc-highlight">Can we select particular fields from the input message ?</a></li><li><a href="#why-protobuf--can-it-support-other-formats-like-json-and-avro-" class="table-of-contents__link toc-highlight">Why Protobuf ? Can it support other formats like JSON and Avro ?</a></li><li><a href="#will-i-have-any-data-loss-if-my-firehose-fails-" class="table-of-contents__link toc-highlight">Will I have any data loss if my Firehose fails ?</a></li><li><a href="#how-does-firehose-handle-failed-messages-" class="table-of-contents__link toc-highlight">How does Firehose handle failed messages ?</a></li><li><a href="#how-does-commits-for-kafka-consumer-works-" class="table-of-contents__link toc-highlight">How does commits for Kafka consumer works ?</a></li><li><a href="#what-all-metrics-are-available-to-monitor-the-kafka-consumer" class="table-of-contents__link toc-highlight">What all metrics are available to monitor the Kafka consumer?</a></li><li><a href="#what-happens-if-my-firehose-gets-restarted" class="table-of-contents__link toc-highlight">What happens if my Firehose gets restarted?</a></li><li><a href="#how-to-configure-the-filter-for-a-proto-field-based-on-some-data" class="table-of-contents__link toc-highlight">How to configure the filter for a proto field based on some data?</a></li><li><a href="#can-i-perform-basic-arithmetic-operations-in-filters" class="table-of-contents__link toc-highlight">Can I perform basic arithmetic operations in filters?</a></li><li><a href="#does-log-sink-work-for-any-complex-data-type-eg-array" class="table-of-contents__link toc-highlight">Does log sink work for any complex data type e.g. array?</a></li><li><a href="#what-are-the-use-cases-of-log-sink" class="table-of-contents__link toc-highlight">What are the use-cases of log sink?</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Open DataOps Foundation © 2024</div></div></div></footer></div>
<script src="/firehose/assets/js/runtime~main.01adef25.js"></script>
<script src="/firehose/assets/js/main.d3e659f8.js"></script>
</body>
</html>